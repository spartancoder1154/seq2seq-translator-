def decode_sequence(test_input):
    # Encode the input sentence
    encoder_states_value = encoder_model.predict(test_input)

    # Initial decoder states
    decoder_states_value = encoder_states_value

    # Start token
    target_seq = np.zeros((1, 1, num_decoder_tokens))
    target_seq[0, 0, target_features_dict['<START>']] = 1.

    decoded_sentence = ''

    stop_condition = False
    while not stop_condition:

        # Run decoder for one timestep
        output_tokens, h, c = decoder_model.predict([target_seq] + decoder_states_value)

        # Pick token with highest probability
        sampled_token_index = np.argmax(output_tokens[0, -1, :])
        sampled_token = reverse_target_features_dict[sampled_token_index]

        # Stop if END token or too long
        if sampled_token == '<END>' or len(decoded_sentence) > max_decoder_seq_length:
            stop_condition = True
        else:
            decoded_sentence += sampled_token + ' '

        # Update target sequence
        target_seq = np.zeros((1, 1, num_decoder_tokens))
        target_seq[0, 0, sampled_token_index] = 1.

        # Update decoder states
        decoder_states_value = [h, c]

    return decoded_sentence.strip()
